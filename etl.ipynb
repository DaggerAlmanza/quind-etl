{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logging:\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_logging():\n",
    "        \"\"\"Configura el sistema de logging para que use un único archivo y agregue nuevos registros.\"\"\"\n",
    "        log_filename = \"data_analysis.log\"\n",
    "\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_filename, mode=\"a\"),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        return logging.getLogger(__name__)\n",
    "    \n",
    "    def report_data_issues(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        data_issues: dict\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Crea un archivo CSV para registrar problemas de calidad de datos.\n",
    "\n",
    "        :param table_name: Nombre de la tabla afectada.\n",
    "        :param data_issues: DataFrame con los datos problemáticos.\n",
    "        :param issue_type: Tipo de problema de datos (e.g., \"duplicados\", \"valores no válidos\").\n",
    "        \"\"\"\n",
    "        # Crear el nombre del archivo con fecha y hora completa\n",
    "        timestamp = datetime..datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        file_name = f\"{table_name}_{timestamp}.csv\"\n",
    "        file_path = os.path.join(self.output_dir, file_name)\n",
    "\n",
    "        try:\n",
    "            # Guardar el DataFrame como un archivo CSV\n",
    "            data_issues.to_csv(file_path, index=False)\n",
    "            self.logger.info(f\"Archivo CSV generado: {file_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar el archivo CSV para {table_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_SHEETS = [\"film\", \"inventory\", \"rental\", \"customer\", \"store\"]\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, logger: logging.Logger):\n",
    "        self.logger = logger\n",
    "        self.df = None\n",
    "\n",
    "    def load_and_validate_excel(self, file_path: str, table: str):\n",
    "        \"\"\"\n",
    "        Carga y valida un archivo Excel.\n",
    "\n",
    "        :param file_path: Ruta del archivo Excel a cargar.\n",
    "        \"\"\"\n",
    "        # Verificar si el archivo existe\n",
    "        if not os.path.isfile(file_path):\n",
    "            self.logger.error(f\"El archivo '{file_path}' no existe o no es válido.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Leer las hojas del archivo Excel\n",
    "            all_sheets = pd.ExcelFile(file_path).sheet_names\n",
    "            cleaned_sheets = [sheet.strip() for sheet in all_sheets]\n",
    "\n",
    "            # Validar que las hojas requeridas estén presentes\n",
    "            missing_sheets = [\n",
    "                sheet for sheet in REQUIRED_SHEETS if sheet not in cleaned_sheets\n",
    "            ]\n",
    "            if missing_sheets:\n",
    "                self.logger.error(\n",
    "                    f\"El archivo '{file_path}' no contiene las hojas requeridas: {missing_sheets}.\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "            # Cargar cada hoja requerida en un DataFrame\n",
    "            self.df = pd.read_excel(file_path, sheet_name=table)\n",
    "            self.logger.info(f\"Archivo '{file_path}' cargado correctamente.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al cargar el archivo Excel '{file_path}': {str(e)}\")\n",
    "\n",
    "    def dataframe_pre_analyze(self, table_name: str):\n",
    "        \"\"\"\n",
    "        Analiza un DataFrame para detectar valores nulos, duplicados y tipos de\n",
    "        datos y guarda el resultado en un diccionario y en el registro de logger.\n",
    "\n",
    "        Args:\n",
    "            df: pandas DataFrame a analizar\n",
    "            table_name: nombre de la tabla para el reporte\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Iniciando pre-análisis de la tabla {table_name}\")\n",
    "        \n",
    "        # Diccionario para almacenar el análisis\n",
    "        analysis_report = {\n",
    "            \"table_name\": table_name,\n",
    "            \"general_info\": {\n",
    "                \"num_rows\": len(self.df),\n",
    "                \"num_columns\": len(self.df.columns)\n",
    "            },\n",
    "            \"data_types\": self.df.dtypes.to_dict(),\n",
    "            \"null_values\": self.df.isnull().sum().to_dict(),\n",
    "            \"duplicates\": {\"num_duplicates\": self.df.duplicated().sum()},\n",
    "            \"basic_stats\": self.df.describe().to_dict()\n",
    "        }\n",
    "\n",
    "        # Valores únicos para columnas categóricas\n",
    "        categorical_columns = self.df.select_dtypes(include=[\"object\"]).columns\n",
    "        unique_values = {col: self.df[col].nunique() for col in categorical_columns}\n",
    "        analysis_report[\"unique_values\"] = unique_values\n",
    "\n",
    "        # Registro en logger\n",
    "        self.logger.info(f\"Reporte de pre-análisis: {analysis_report}\")\n",
    "        return analysis_report\n",
    "\n",
    "    def clean_numeric_columns(self, table_name: str, numeric_columns: list):\n",
    "        \"\"\"\n",
    "        Limpia las columnas numéricas, eliminando filas con valores no numéricos\n",
    "\n",
    "        Args:\n",
    "            table_name: nombre de la tabla\n",
    "            numeric_columns: lista de columnas que deben ser numéricas\n",
    "        \"\"\"\n",
    "        rows_before = len(self.df)\n",
    "        non_numeric_values_dict = {}\n",
    "\n",
    "        for column in numeric_columns:\n",
    "            if column in self.df.columns:\n",
    "                # Verificar valores no numéricos\n",
    "                non_numeric_mask = pd.to_numeric(self.df[column], errors=\"coerce\").isna()\n",
    "                if non_numeric_mask.any():\n",
    "                    non_numeric_values = self.df[non_numeric_mask][column].unique()\n",
    "                    non_numeric_values_dict[f\"{table_name}_{column}\"] = non_numeric_values.tolist()\n",
    "                    self.df.drop(self.df[non_numeric_mask].index, inplace=True)\n",
    "\n",
    "                    # Convertir al tipo numérico adecuado\n",
    "                    if any(keyword in column for keyword in [\"id\", \"year\", \"length\", \"num_voted\"]):\n",
    "                        self.df[column] = pd.to_numeric(self.df[column], errors=\"coerce\").astype(\"Int64\")\n",
    "                    else:\n",
    "                        self.df[column] = pd.to_numeric(self.df[column], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "        if non_numeric_values_dict:\n",
    "            self.logger.warning(f\"Valores no numéricos encontrados en {table_name}: {non_numeric_values_dict}\")\n",
    "        \n",
    "        rows_after = len(self.df)\n",
    "        self.logger.info(f\"Se eliminaron {rows_before - rows_after} filas con valores no numéricos en {table_name}\")\n",
    "        \n",
    "        # Limpiar y convertir columnas de fecha\n",
    "        date_columns = [col for col in self.df.columns if \"date\" in col.lower()]\n",
    "        for col in date_columns:\n",
    "            self.df[col] = pd.to_datetime(self.df[col].str.strip().str.lstrip(\"'\\\"\").str.rstrip(\"'\\\"\"), errors='coerce')\n",
    "\n",
    "    def analyze_dataframe(self, table_name: str):\n",
    "        \"\"\"\n",
    "        Analiza un DataFrame para detectar valores nulos, duplicados y tipos de datos\n",
    "\n",
    "        Args:\n",
    "            table_name: nombre de la tabla para el reporte\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Dimensiones después de limpieza de {table_name}: {self.df.shape}\")\n",
    "        data_types = {column: dtype for column, dtype in self.df.dtypes.items()}\n",
    "        self.logger.info(f\"Tipos de datos en {table_name}: {data_types}\")\n",
    "\n",
    "        duplicates = self.df.duplicated().sum()\n",
    "        if duplicates > 0:\n",
    "            self.logger.warning(f\"Se encontraron {duplicates} filas duplicadas\")\n",
    "        return self.df\n",
    "\n",
    "    def verify_relationships(self, dfs: dict):\n",
    "        \"\"\"\n",
    "        Verifica la integridad referencial entre las tablas\n",
    "\n",
    "        Args:\n",
    "            dfs: diccionario con los DataFrames {nombre_tabla: DataFrame}\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Verificando integridad referencial entre tablas\")\n",
    "\n",
    "        # Verificar integridad referencial entre film y inventory\n",
    "        if \"film\" in dfs and \"inventory\" in dfs:\n",
    "            invalid_films = set(dfs[\"inventory\"][\"film_id\"]) - set(dfs[\"film\"][\"film_id\"])\n",
    "            if invalid_films:\n",
    "                self.logger.error(f\"Film_ids en inventory que no existen en film: {len(invalid_films)}\")\n",
    "                dfs[\"inventory\"] = dfs[\"inventory\"][~dfs[\"inventory\"][\"film_id\"].isin(invalid_films)]\n",
    "\n",
    "        # Verificar integridad referencial entre inventory y store\n",
    "        if \"inventory\" in dfs and \"store\" in dfs:\n",
    "            invalid_stores = set(dfs[\"inventory\"][\"store_id\"]) - set(dfs[\"store\"][\"store_id\"])\n",
    "            if invalid_stores:\n",
    "                self.logger.error(f\"Store_ids en inventory que no existen en store: {len(invalid_stores)}\")\n",
    "                dfs[\"inventory\"] = dfs[\"inventory\"][~dfs[\"inventory\"][\"store_id\"].isin(invalid_stores)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 06:20:48,865 [INFO] ==================================================\n",
      "Cargando tabla: film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 06:20:50,276 [INFO] Archivo '/home/dager/Documentos/Proyectos/Pruebas Técnica/Quind/Films_2 (3).xlsx' cargado correctamente.\n",
      "2024-11-15 06:20:50,278 [INFO] Iniciando pre-análisis de la tabla film\n",
      "2024-11-15 06:20:50,296 [INFO] Reporte de pre-análisis: {'table_name': 'film', 'general_info': {'num_rows': 1003, 'num_columns': 14}, 'data_types': {'film_id': dtype('O'), ' title': dtype('O'), ' description': dtype('O'), ' release_year': dtype('O'), ' language_id': dtype('int64'), ' original_language_id': dtype('O'), ' rental_duration': dtype('int64'), ' rental_rate': dtype('O'), ' length': dtype('O'), ' replacement_cost': dtype('O'), ' num_voted_users': dtype('O'), ' rating': dtype('O'), ' special_features': dtype('O'), 'last_update': dtype('O')}, 'null_values': {'film_id': 0, ' title': 0, ' description': 0, ' release_year': 0, ' language_id': 0, ' original_language_id': 0, ' rental_duration': 0, ' rental_rate': 0, ' length': 0, ' replacement_cost': 0, ' num_voted_users': 0, ' rating': 0, ' special_features': 0, 'last_update': 0}, 'duplicates': {'num_duplicates': np.int64(3)}, 'basic_stats': {' language_id': {'count': 1003.0, 'mean': 1.0, 'std': 0.0, 'min': 1.0, '25%': 1.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}, ' rental_duration': {'count': 1003.0, 'mean': 4.982053838484546, 'std': 1.4105664018205, 'min': 3.0, '25%': 4.0, '50%': 5.0, '75%': 6.0, 'max': 7.0}}, 'unique_values': {'film_id': 1000, ' title': 1000, ' description': 1000, ' release_year': 4, ' original_language_id': 1, ' rental_rate': 6, ' length': 145, ' replacement_cost': 28, ' num_voted_users': 749, ' rating': 5, ' special_features': 4, 'last_update': 1}}\n",
      "2024-11-15 06:20:50,303 [WARNING] Valores no numéricos encontrados en film: {'film_film_id': ['x98', 'xa291']}\n",
      "2024-11-15 06:20:50,304 [INFO] Se eliminaron 2 filas con valores no numéricos en film\n",
      "2024-11-15 06:20:50,313 [INFO] Dimensiones después de limpieza de film: (1001, 14)\n",
      "2024-11-15 06:20:50,315 [INFO] Tipos de datos en film: {'film_id': Int64Dtype(), ' title': dtype('O'), ' description': dtype('O'), ' release_year': dtype('O'), ' language_id': dtype('int64'), ' original_language_id': dtype('O'), ' rental_duration': dtype('int64'), ' rental_rate': dtype('O'), ' length': dtype('O'), ' replacement_cost': dtype('O'), ' num_voted_users': dtype('O'), ' rating': dtype('O'), ' special_features': dtype('O'), 'last_update': dtype('<M8[ns]')}\n",
      "2024-11-15 06:20:50,322 [WARNING] Se encontraron 3 filas duplicadas\n",
      "2024-11-15 06:20:50,324 [INFO] ==================================================\n",
      "Cargando tabla: inventory\n",
      "2024-11-15 06:20:51,753 [INFO] Archivo '/home/dager/Documentos/Proyectos/Pruebas Técnica/Quind/Films_2 (3).xlsx' cargado correctamente.\n",
      "2024-11-15 06:20:51,755 [INFO] Iniciando pre-análisis de la tabla inventory\n",
      "2024-11-15 06:20:51,766 [INFO] Reporte de pre-análisis: {'table_name': 'inventory', 'general_info': {'num_rows': 4581, 'num_columns': 4}, 'data_types': {'inventory_id': dtype('int64'), 'film_id': dtype('int64'), ' store_id': dtype('O'), ' last_update': dtype('O')}, 'null_values': {'inventory_id': 0, 'film_id': 0, ' store_id': 0, ' last_update': 0}, 'duplicates': {'num_duplicates': np.int64(0)}, 'basic_stats': {'inventory_id': {'count': 4581.0, 'mean': 2291.0, 'std': 1322.5651212700266, 'min': 1.0, '25%': 1146.0, '50%': 2291.0, '75%': 3436.0, 'max': 4581.0}, 'film_id': {'count': 4581.0, 'mean': 500.9362584588518, 'std': 288.58965041931407, 'min': 1.0, '25%': 253.0, '50%': 496.0, '75%': 753.0, 'max': 1000.0}}, 'unique_values': {' store_id': 4, ' last_update': 1}}\n",
      "2024-11-15 06:20:51,767 [INFO] Se eliminaron 0 filas con valores no numéricos en inventory\n",
      "2024-11-15 06:20:51,780 [INFO] Dimensiones después de limpieza de inventory: (4581, 4)\n",
      "2024-11-15 06:20:51,782 [INFO] Tipos de datos en inventory: {'inventory_id': dtype('int64'), 'film_id': dtype('int64'), ' store_id': dtype('O'), ' last_update': dtype('<M8[ns]')}\n",
      "2024-11-15 06:20:51,786 [INFO] ==================================================\n",
      "Cargando tabla: rental\n",
      "2024-11-15 06:20:54,015 [INFO] Archivo '/home/dager/Documentos/Proyectos/Pruebas Técnica/Quind/Films_2 (3).xlsx' cargado correctamente.\n",
      "2024-11-15 06:20:54,016 [INFO] Iniciando pre-análisis de la tabla rental\n",
      "2024-11-15 06:20:54,064 [INFO] Reporte de pre-análisis: {'table_name': 'rental', 'general_info': {'num_rows': 16044, 'num_columns': 7}, 'data_types': {'rental_id': dtype('int64'), ' rental_date': dtype('O'), ' inventory_id': dtype('int64'), ' customer_id': dtype('int64'), ' return_date': dtype('O'), ' staff_id': dtype('int64'), ' last_update': dtype('O')}, 'null_values': {'rental_id': 0, ' rental_date': 0, ' inventory_id': 0, ' customer_id': 0, ' return_date': 0, ' staff_id': 0, ' last_update': 0}, 'duplicates': {'num_duplicates': np.int64(0)}, 'basic_stats': {'rental_id': {'count': 16044.0, 'mean': 8025.371478434306, 'std': 4632.777248876794, 'min': 1.0, '25%': 4013.75, '50%': 8025.5, '75%': 12037.25, 'max': 16049.0}, ' inventory_id': {'count': 16044.0, 'mean': 2291.8425579655946, 'std': 1322.2106432491478, 'min': 1.0, '25%': 1154.0, '50%': 2291.0, '75%': 3433.0, 'max': 4581.0}, ' customer_id': {'count': 16044.0, 'mean': 297.14316878583895, 'std': 172.45313648154516, 'min': 1.0, '25%': 148.0, '50%': 296.0, '75%': 446.0, 'max': 599.0}, ' staff_id': {'count': 16044.0, 'mean': 1.49887808526552, 'std': 0.500014324144054, 'min': 1.0, '25%': 1.0, '50%': 1.0, '75%': 2.0, 'max': 2.0}}, 'unique_values': {' rental_date': 15815, ' return_date': 15837, ' last_update': 2}}\n",
      "2024-11-15 06:20:54,066 [INFO] Se eliminaron 0 filas con valores no numéricos en rental\n",
      "2024-11-15 06:20:54,126 [INFO] Dimensiones después de limpieza de rental: (16044, 7)\n",
      "2024-11-15 06:20:54,128 [INFO] Tipos de datos en rental: {'rental_id': dtype('int64'), ' rental_date': dtype('<M8[ns]'), ' inventory_id': dtype('int64'), ' customer_id': dtype('int64'), ' return_date': dtype('<M8[ns]'), ' staff_id': dtype('int64'), ' last_update': dtype('<M8[ns]')}\n",
      "2024-11-15 06:20:54,135 [INFO] ==================================================\n",
      "Cargando tabla: customer\n",
      "2024-11-15 06:20:55,411 [INFO] Archivo '/home/dager/Documentos/Proyectos/Pruebas Técnica/Quind/Films_2 (3).xlsx' cargado correctamente.\n",
      "2024-11-15 06:20:55,412 [INFO] Iniciando pre-análisis de la tabla customer\n",
      "2024-11-15 06:20:55,431 [INFO] Reporte de pre-análisis: {'table_name': 'customer', 'general_info': {'num_rows': 1392, 'num_columns': 11}, 'data_types': {'customer_id': dtype('int64'), ' store_id': dtype('int64'), ' first_name': dtype('O'), ' last_name': dtype('O'), ' email': dtype('O'), ' address_id': dtype('int64'), ' active': dtype('int64'), ' create_date': dtype('O'), ' last_update': dtype('O'), ' customer_id_old': dtype('O'), ' segment': dtype('O')}, 'null_values': {'customer_id': 0, ' store_id': 0, ' first_name': 0, ' last_name': 0, ' email': 0, ' address_id': 0, ' active': 0, ' create_date': 0, ' last_update': 0, ' customer_id_old': 0, ' segment': 0}, 'duplicates': {'num_duplicates': np.int64(0)}, 'basic_stats': {'customer_id': {'count': 1392.0, 'mean': 696.5, 'std': 401.9800990098888, 'min': 1.0, '25%': 348.75, '50%': 696.5, '75%': 1044.25, 'max': 1392.0}, ' store_id': {'count': 1392.0, 'mean': 1.480603448275862, 'std': 0.49980319139106466, 'min': 1.0, '25%': 1.0, '50%': 1.0, '75%': 2.0, 'max': 2.0}, ' address_id': {'count': 1392.0, 'mean': 476.35632183908046, 'std': 187.71726308104883, 'min': 5.0, '25%': 353.75, '50%': 606.0, '75%': 606.0, 'max': 606.0}, ' active': {'count': 1392.0, 'mean': 0.9892241379310345, 'std': 0.10328313624296202, 'min': 0.0, '25%': 1.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}}, 'unique_values': {' first_name': 929, ' last_name': 1187, ' email': 1392, ' create_date': 3, ' last_update': 2, ' customer_id_old': 794, ' segment': 4}}\n",
      "2024-11-15 06:20:55,432 [INFO] Se eliminaron 0 filas con valores no numéricos en customer\n",
      "2024-11-15 06:20:55,440 [INFO] Dimensiones después de limpieza de customer: (1392, 11)\n",
      "2024-11-15 06:20:55,441 [INFO] Tipos de datos en customer: {'customer_id': dtype('int64'), ' store_id': dtype('int64'), ' first_name': dtype('O'), ' last_name': dtype('O'), ' email': dtype('O'), ' address_id': dtype('int64'), ' active': dtype('int64'), ' create_date': dtype('<M8[ns]'), ' last_update': dtype('<M8[ns]'), ' customer_id_old': dtype('O'), ' segment': dtype('O')}\n",
      "2024-11-15 06:20:55,448 [INFO] ==================================================\n",
      "Cargando tabla: store\n",
      "2024-11-15 06:20:56,589 [INFO] Archivo '/home/dager/Documentos/Proyectos/Pruebas Técnica/Quind/Films_2 (3).xlsx' cargado correctamente.\n",
      "2024-11-15 06:20:56,590 [INFO] Iniciando pre-análisis de la tabla store\n",
      "2024-11-15 06:20:56,602 [INFO] Reporte de pre-análisis: {'table_name': 'store', 'general_info': {'num_rows': 2, 'num_columns': 4}, 'data_types': {'store_id': dtype('int64'), 'manager_staff_id': dtype('int64'), ' address_id': dtype('int64'), ' last_update': dtype('O')}, 'null_values': {'store_id': 0, 'manager_staff_id': 0, ' address_id': 0, ' last_update': 0}, 'duplicates': {'num_duplicates': np.int64(0)}, 'basic_stats': {'store_id': {'count': 2.0, 'mean': 1.5, 'std': 0.7071067811865476, 'min': 1.0, '25%': 1.25, '50%': 1.5, '75%': 1.75, 'max': 2.0}, 'manager_staff_id': {'count': 2.0, 'mean': 1.5, 'std': 0.7071067811865476, 'min': 1.0, '25%': 1.25, '50%': 1.5, '75%': 1.75, 'max': 2.0}, ' address_id': {'count': 2.0, 'mean': 1.5, 'std': 0.7071067811865476, 'min': 1.0, '25%': 1.25, '50%': 1.5, '75%': 1.75, 'max': 2.0}}, 'unique_values': {' last_update': 1}}\n",
      "2024-11-15 06:20:56,603 [INFO] Se eliminaron 0 filas con valores no numéricos en store\n",
      "2024-11-15 06:20:56,606 [INFO] Dimensiones después de limpieza de store: (2, 4)\n",
      "2024-11-15 06:20:56,607 [INFO] Tipos de datos en store: {'store_id': dtype('int64'), 'manager_staff_id': dtype('int64'), ' address_id': dtype('int64'), ' last_update': dtype('<M8[ns]')}\n",
      "2024-11-15 06:20:56,609 [INFO] Verificando integridad referencial entre tablas\n",
      "2024-11-15 06:20:56,611 [ERROR] Film_ids en inventory que no existen en film: 2\n",
      "2024-11-15 06:20:56,620 [ERROR] Error general en el procesamiento: 'store_id'\n"
     ]
    }
   ],
   "source": [
    "logger = Logging().setup_logging()\n",
    "processor = DataProcessor(logger)\n",
    "\n",
    "try:\n",
    "    numeric_columns = {\n",
    "        \"inventory\": [\"inventory_id\", \"film_id\", \"store_id\"],\n",
    "        \"film\": [\"film_id\", \"release_year\", \"length\", \"num_voted_users\", \"language_id\", \"rental_rate\", \"replacement_cost\", \"rental_duration\"],\n",
    "        \"rental\": [\"rental_id\", \"inventory_id\", \"customer_id\", \"staff_id\"],\n",
    "        \"customer\": [\"customer_id\"],\n",
    "        \"store\": [\"store_id\", \"address_id\", \"active\"]\n",
    "    }\n",
    "\n",
    "    excel_file = \"/home/dager/Documentos/Proyectos/Pruebas Técnica/Quind/Films_2 (3).xlsx\"\n",
    "    dataframes = {}\n",
    "\n",
    "    for table in REQUIRED_SHEETS:\n",
    "        try:\n",
    "            logger.info(f\"{'=' * 50}\\nCargando tabla: {table}\")\n",
    "            processor.load_and_validate_excel(excel_file, table)\n",
    "\n",
    "            # Pre-analizar la tabla\n",
    "            processor.dataframe_pre_analyze(table)\n",
    "\n",
    "            if table in numeric_columns:\n",
    "                processor.clean_numeric_columns(table, numeric_columns[table])\n",
    "\n",
    "            df = processor.analyze_dataframe(table)\n",
    "            dataframes[table] = df\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error al procesar la tabla {table}: {str(e)}\")\n",
    "\n",
    "    processor.verify_relationships(dataframes)\n",
    "\n",
    "    output_file = f\"cleaned_data_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        for table_name, df in dataframes.items():\n",
    "            df.to_excel(writer, sheet_name=table_name, index=False)\n",
    "    logger.info(f\"Datos limpios guardados en: {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error general en el procesamiento: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
